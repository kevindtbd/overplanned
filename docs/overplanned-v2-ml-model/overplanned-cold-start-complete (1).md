# Overplanned — Cold Start: Complete Strategy

*Internal Reference · February 2026*  
*Synthesizes: bootstrap-deepdive.md, backfill-enrichment.md, onboarding-flow-strategy.md, subflow-recommendation-architecture.md, heuristics-addendum.md*

---

## The Problem, Precisely

Every ML model in the architecture requires behavioral data that doesn't exist on Day 0. The recommendation system needs to work on the first trip for the first user — before any signals have been collected, before any ranking model has been trained, before the system has observed a single preference.

The cold start problem has two distinct dimensions that require separate solutions:

**Item cold start** — the ActivityNode corpus needs pre-populated quality signals before any user sees it. A recommendation system without items to recommend is blocked entirely. This is solved by Pipeline C (scraping + LLM extraction) before launch, independent of user behavior.

**User cold start** — a new user arrives with no behavioral history. The system has to infer who they are and what they want from the minimum possible upfront input. This is the harder problem and the focus of this document.

The strategy is a layered stack of five sources that together give the LLM ranker enough structured signal to generate a meaningfully personalized first itinerary — better than anything a standard travel app produces before any behavioral data exists.

---

## The Five-Source Stack

### Source 1 — Synthetic Agent Training

**What it is:** 600 synthetic traveler profiles across 12 archetypes, each with pre-calibrated persona dimension values. Generated offline before any real user exists. Cost: ~$20 one-time.

**What it solves:** Persona dimension initialization. The LLM ranker doesn't start from uniform priors — it starts from a distribution of known traveler types, each with realistic dimension value combinations. A new cold user is matched to their closest archetype at onboarding completion, and that archetype's dimension values seed their persona state.

**What it does not solve:** Training the ranking model. Synthetic signals are excluded from ranking model training entirely. They are persona seed data only. The ranking model requires real counterfactual context — what alternatives were shown, what was chosen — that synthetic data cannot provide.

**Confidence weight:** 0.3× — used only for persona initialization, never fed into ranking or persona dimension training batches.

**The 12 archetypes (representative):**

| ID | Label | Key dimensions |
|---|---|---|
| A01 | Solo deep diver | high local_bias, high food_priority, low social_energy |
| A02 | Adventure seeker | high adventure_appetite, low pace, low planning_preference |
| A03 | Couples slow travel | low pace, high food_priority, low social_energy |
| A04 | Group maximizer | high social_energy, high pace, medium food_priority |
| A05 | Cultural immersionist | high cultural_depth, low tourist_tolerance, medium pace |
| A06 | Luxury comfort | high budget_sensitivity, medium pace, low adventure |
| A07 | Budget backpacker | low budget_sensitivity, high adventure, high local_bias |
| A08 | Family practical | medium pace, high planning_preference, medium food |
| A09 | Business tripper | high efficiency, low spontaneity, medium food |
| A10 | Festival/nightlife | high social_energy, evening-weighted, low morning |
| A11 | Curious first-timer | balanced across all dimensions — the default assignment |
| A12 | Remote worker | slow pace, high local_bias, low tourist_tolerance |

A11 is the safe default. When onboarding is skipped or signal is insufficient to match any archetype confidently, the system falls back to A11 — the most general, least-offensive starting point.

**Training:** Synthetic agents are generated by prompting Claude with rich archetype definitions and having it simulate 50 trip-planning sessions per archetype, including slot acceptance patterns, pivot behavior, and post-trip ratings. Each session produces a behavioral sequence that initializes the dimension weight vectors without real user data.

---

### Source 2 — Past Trips Backfill

**What it is:** Structured ingestion of a user's historical travel data before they plan their first new trip. Users import or manually enter trips they've already taken. This is a V2 feature scoped for Month 2–3, but the architecture is defined and the signal schema is in place at launch.

**What it solves:** The highest-density cold start input per user. A user who enters 3–5 past trips is providing confirmed positive labels — where they actually went, what they actually did — that reveal stable preference patterns the system couldn't otherwise observe until trip 3 or 4.

**The dual value proposition:** Users get a permanent travel diary (a map of everywhere they've been, searchable and organized) that has value independent of recommendations. Overplanned gets dense persona signal before a single new trip is planned. Product incentive and ML need are aligned.

**Source confidence tiers — permanent, cannot be upgraded:**

| Tier | Source | Confidence Weight | Use in Ranking Model |
|---|---|---|---|
| Tier 1 | In-app behavioral | 1.0× — ground truth | Yes |
| Tier 2 | Structured import (TripIt, booking confirmation) | 0.65× | No |
| Tier 3 | Annotated free-form (user added ratings/notes) | 0.40× | No |
| Tier 4 | Bare free-form (no annotations) | 0.20× | No |

**Critical constraint:** Backfill signals are persona seed data, not ranking model training data. The ranking model requires counterfactual context — what alternatives were available and shown. Backfilled itineraries have no counterfactual. They must never enter ranking model training regardless of tier.

**The ingestion pipeline:**

**Stage 1 — Source classification.** Rules-based, not ML. Determinism required because this output locks the confidence ceiling for everything downstream. Structured import → Tier 2. Screenshot/photo → OCR then free-form. Pasted text with annotations → Tier 3. Bare pasted text → Tier 4. Unreadable → rejected with explanation.

**Stage 2 — LLM extraction.** Free-form and OCR'd submissions pass through Haiku extraction. The prompt instructs the model to output null rather than guess when a field is ambiguous. A hallucinated venue is strictly worse than a gap. Conservative extraction philosophy: prefer 8 high-confidence extractions from a 15-item itinerary over 15 low-confidence ones.

Each extracted record contains: venue name, inferred category, date or date range, geographic context, sentiment signal (explicit ratings, qualitative descriptors, phrases indicating strong positive or negative reaction).

**Stage 3 — Entity resolution.** Extracted venue names matched against the World Knowledge vector database via fuzzy matching. Records that cannot be resolved above 0.80 confidence are flagged as unresolved. Unresolved records are stored in the travel diary (for user-facing completeness) but excluded from persona scoring.

**Stage 4 — Anomaly and integrity checks.** Context-aware suppression: a user who went to a waterpark once on a family trip does not necessarily prefer waterparks. If the trip is tagged Family, the waterpark entry is suppressed in solo preference modeling. This is high-value signal from a trivially low-effort input.

**What the persona extracts from backfill:**
- Category distribution across multiple trips → vibe_tag_affinity weights
- Pace signal (day density, hours between slots) → pace_preference
- Food:activity ratio across trips → food_priority
- Local vs. landmark balance → local_vs_tourist_bias
- Sentiment-tagged venues → positive/negative dimension labels

**Build sequence:**
- Launch: diary view + trip import (artifact value, persona seed)
- V2 Month 2–3: annotations, star ratings, "would return" flag (pushes Tier 4 → Tier 3)
- V2 Month 3+: photo attachment + scene classification (implicit signal without asking)
- Scale 500+ users: persona-vs-backfill delta logging (foundation for future constraint modeling)

---

### Source 3 — LLM / ChatGPT Itinerary Import

**What it is:** A user pastes an itinerary they previously generated in ChatGPT, another AI tool, or any external source. One paste, one Haiku extraction call, full trip shape parsed.

**What it solves:** The highest signal-density cold start input per user-interaction cost. A complete itinerary paste is worth more than 2 completed in-app trips in terms of preference signal extraction — it reveals the full shape of how the user thinks about a trip before they've made a single in-app decision.

**What the LLM extraction pass pulls from a paste:**

- Destination(s) → destination affinity initialization
- Category distribution across all slots → vibe_tag_affinity starting weights
- Pace signal: how many slots per day, are there gaps, what's the day density → pace_preference
- Food:activity ratio → food_priority
- Local vs. tourist balance: are the venues landmarks or hidden gems → local_vs_tourist_bias
- Day-part pattern: morning-heavy or evening-heavy → energy_curve shape
- Trip duration preference → planning_preference signal

A user who pastes a 4-day Tokyo itinerary with 3 ramen stops, 2 izakayas, zero temples, and gaps mid-afternoon has handed the system a complete persona sketch in one action.

**Confidence weight:** Treat as Tier 3 equivalent (0.40×) for persona dimension training. Do not enter into ranking model training — no counterfactual available. The signal is genuine but it reflects what an LLM thought this user wanted, not what they actually did.

**Extraction philosophy:** Same conservative approach as backfill — null over hallucination. If the paste is ambiguous about category (is "Senso-ji" cultural, spiritual, or tourist landmark?), the system extracts the venue and resolves category via entity matching against ActivityNodes, not LLM inference.

**Persona update timing:** Extraction runs async at paste submission. Persona dimensions update before the user reaches destination input. By the time they set dates, the ranker already has a meaningful prior. The transition is invisible.

**Trust and integrity:** Commercial content injection is possible (a venue owner pastes a fake "user itinerary" to seed positive signals). Apply the same coordinated pumping detector logic as for shared trip imports: flag accounts where paste content clusters suspiciously around a small set of venues, cross-reference paste author vs. importer patterns.

---

### Source 4 — Onboarding UX Signals

**What it is:** The structured signal collection embedded in the onboarding flow itself. Every screen in onboarding is designed to produce a specific persona dimension reading, not just collect preferences.

**Design principle:** Revealed preference over self-report. Scenario cards (choosing between two vivid real moments) produce more accurate dimension readings than tag selection (what users aspire to be). The sequence is designed so that 2 required taps resolve 4–5 persona dimensions, with optional inputs extending coverage.

**The signal map by screen:**

**Screen 0 — The hook ("Plan a trip" vs. "Show me something"):**  
Intent confidence seed. "Show me something" = high spontaneity, lower planning_preference, higher adventure_appetite. Logged as a 0.4× confidence prior — soft signal, but costs nothing.

**Screen 1 — "Who's going?" (Just me / Two of us / Small group / Big group):**  
Single tap resolves social_energy baseline and trip type. Narrows from 600 synthetic archetypes to ~80 relevant ones. Probably the highest information-per-tap ratio of any screen in the product. Solo vs. group have almost no persona overlap — early branching eliminates noise from the start.

**Screen 2 — Destination + dates:**  
Destination choice loads the destination_persona_prior (see Source 5 below) and initializes destination affinity. Dates give trip_length for pacing model initialization.

**Screen 3 — Scenario cards (2 cards, required):**  
Each card resolves 2–3 persona dimensions from a single tap. Two cards = 4–6 dimension reads. These are the highest-confidence onboarding signals because they are revealed preference: the user is choosing between two real moments, not selecting tags that describe their ideal self.

Example card: *"Which afternoon sounds better? (A) Tiny bar no one knows about, standing room only, locals at counter. (B) Rooftop with great views and decent cocktails, a bit touristy but the sunset is worth it."* A single tap resolves `local_vs_tourist_bias` + `social_energy` simultaneously.

Confidence weight: 1.0× for persona dimension initialization (the baseline). The highest-confidence source available at onboarding without requiring past trip data.

**Screen 4 — "Name a trip you've loved" (optional, free text):**  
LLM extraction runs on city names mentioned → cross-reference against ActivityNode vibe profiles → infer activity category affinities → seed persona. Tokyo mention implies food curiosity, walkability, density tolerance. Iceland mention implies outdoor/nature emphasis, experience over dining, lower social energy.

Confidence weight: 1.5× — higher than scenario cards because it's reflective and multi-dimensional, not reactive to a forced binary choice.

**Skip path signal design:** No path through onboarding produces a null persona. Every interaction including avoidance is data.
- Skipping scenario cards → maps to A11 archetype (most general default)
- Fast skip (< 2s per screen) → experienced traveler or skeptical user → reduce confidence on all seed dimensions, increase novelty weighting on first trip
- Slow skip (> 10s on a screen with no action) → uncertainty signal → widen confidence intervals on that dimension, don't overcorrect

**Persona state after full onboarding completion:**

```
Example output for a user who completed all screens:
{
  "local_vs_tourist_bias": { "value": 0.78, "confidence": 0.87 },
  "food_priority":         { "value": 0.72, "confidence": 0.82 },
  "pace_preference":       { "value": -0.3, "confidence": 0.35 },
  "social_energy":         { "value": -0.4, "confidence": 0.55 },
  "budget_sensitivity":    { "value": null, "confidence": 0.0  },  ← not yet observed
  "adventure_appetite":    { "value": 0.2,  "confidence": 0.40 }
}
```

Dimensions with null confidence are not guessed — the LLM ranker treats them as unknown and uses archetype priors until behavioral signals fill them in.

---

### Source 5 — Destination Prior

**What it is:** A static lookup that nudges a new user's persona toward the real traveler distribution for their chosen destination. Built once from aggregated Reddit, blog, and review corpus data. Updated quarterly.

**What it solves:** Destination choice is a signal. A user heading to Osaka for 4 days vs. Kyoto for 4 days is revealing something about pace preference and food vs. culture weighting before they've answered a question. Tokyo and Bali attract structurally different traveler profiles. This is not demographic stereotyping — it's a distributional prior derived from actual travel behavior patterns in the corpus.

**How it's built:** For each seeded city, aggregate the behavioral patterns of all travelers mentioned in Reddit posts, blogs, and review platforms. Extract the dominant dimension distribution. Normalize into a `destination_persona_prior` vector per city that represents the soft archetype distribution associated with that destination.

**How it's applied:** After a user enters their destination on Screen 2, their persona seed is softly nudged toward the destination prior — not overwritten. If their onboarding signals conflict with the destination prior, the onboarding signals win. The prior is a weak initialization, not a constraint.

```python
def apply_destination_prior(
    persona_seed: PersonaSeed,
    destination_prior: DestinationPrior,
    prior_weight: float = 0.15  # soft nudge only
) -> PersonaSeed:
    for dimension in persona_seed.dimensions:
        if persona_seed[dimension].confidence < 0.3:
            # Low confidence dimension: let the prior nudge it
            blended = (
                persona_seed[dimension].value * (1 - prior_weight) +
                destination_prior[dimension] * prior_weight
            )
            persona_seed[dimension].value = blended
        # High confidence dimensions: prior has no effect
    return persona_seed
```

**Confidence weight:** 0.15× applied only to low-confidence dimensions. Not a training signal — a soft initialization prior only.

---

### Source 6 — Collaborative Filtering Warm Start (activates at 50+ warm users)

**What it is:** Once 50+ real users have completed 3+ trips each, a new cold user's persona seed is supplemented by the centroid of real warm users whose onboarding answers most closely resembled theirs. This replaces the pure synthetic archetype prior with a prior derived from real behavioral patterns.

**What it solves:** The gap between "what we guessed about this archetype" and "what this archetype actually does." Synthetic archetypes are designed from research and intuition. Real warm users reveal patterns the synthetic data didn't anticipate — categories that cluster unexpectedly, pace patterns that don't match the archetype label, food behaviors that vary by destination in ways the archetype didn't model.

**How it works:**

1. At onboarding completion, encode the new user's scenario card responses and destination as a feature vector.
2. Find the K nearest warm users in that feature space (K=10 to start).
3. Take the centroid of their final persona dimension values after 3+ trips.
4. Blend with synthetic archetype prior: `0.6 × collab_centroid + 0.4 × archetype_prior`.
5. Use blended values as the cold-start persona seed.

**Build trigger:** 50 warm users with 3+ completed trips. Before that threshold, pure synthetic archetypes. The transition is automatic — no product work required when the threshold is crossed.

**Important constraint:** Collaborative filtering at this stage is only used for persona initialization, not for ranking. You are not recommending "users like you also liked X" — you are initializing "users like you started with these dimension values." This distinction matters for privacy (no cross-user behavioral disclosure) and for model integrity (the ranking model still learns from this user's own signals, not from neighbors' choices).

---

## The LLM Ranker's Full Input at Trip 1

With all sources active, here is the complete structured input the LLM ranker has before generating a first itinerary for a cold user who completed onboarding, entered past trips, and pasted a ChatGPT itinerary:

```
{
  "archetype_prior": "A03 (Couples slow travel) — from scenario cards",
  "collab_supplement": "centroid of 10 warm users matching onboarding profile",
  "destination_prior": "Osaka — nudge toward food-forward, moderate pace distribution",
  
  "persona_dimensions": {
    "local_vs_tourist_bias":  { "value": 0.78, "confidence": 0.87, "sources": ["scenario_card", "chatgpt_import"] },
    "food_priority":          { "value": 0.82, "confidence": 0.91, "sources": ["scenario_card", "backfill", "chatgpt_import"] },
    "pace_preference":        { "value": -0.4, "confidence": 0.68, "sources": ["backfill", "chatgpt_import", "destination_prior"] },
    "social_energy":          { "value": -0.3, "confidence": 0.55, "sources": ["screen_1", "scenario_card"] },
    "adventure_appetite":     { "value": 0.2,  "confidence": 0.40, "sources": ["free_text"] },
    "budget_sensitivity":     { "value": null,  "confidence": 0.0,  "sources": [] }
  },
  
  "positive_labels": [
    { "category": "standing_bar", "confidence": 0.40, "source": "chatgpt_import" },
    { "category": "local_ramen",  "confidence": 0.65, "source": "backfill_tier2" },
    { "category": "market",       "confidence": 0.40, "source": "backfill_tier4" }
  ],
  
  "negative_labels": [],  // ← THE GAP. No negatives until first in-app swap.
  
  "candidate_pool": "Osaka ActivityNodes, Qdrant vector search on persona embedding",
  "trip_length": 4,
  "group_type": "couple"
}
```

This is a well-initialized ranker. The first itinerary for a user who completes this path will be meaningfully personalized from the first slot.

---

## The One Remaining Gap — No Negative Labels

Every source in the stack produces positive signal: what the user has done, liked, chosen, or indicated preference for. None of them produce negative labels.

The ranking model needs both. BPR (Bayesian Personalized Ranking) specifically trains on accept/skip pairs — the contrast between what was accepted and what was seen but not chosen. Without negatives, the model knows what to surface more of, but not what to actively avoid.

**The gap is structurally unavoidable.** Negative labels require the system to show candidates and observe rejection. That only happens in-app. The first swap is the first negative label. There is no offline substitute.

**The LLM ranker's behavior until negatives arrive:** The ranker should treat all cold-user rankings as "confident positive guesses with high uncertainty on the negatives." Operationally this means:

- Don't double down on any category until a positive signal has been confirmed by acceptance behavior, not just backfill or import
- Maintain diversity across the first itinerary even when the persona strongly suggests a category preference — if the user actually dislikes something the backfill implied they liked, a diverse first itinerary surfaces that signal earlier
- The first swap signal (1.0× weight) is prioritized immediately for persona update regardless of cold-user quarantine for the ranking model — it's the first genuine negative label and should be acted on for narration and future slot suggestions even if it doesn't yet enter ranking model training

**System prompt instruction for cold-user LLM ranker:**

```
You are ranking candidates for a user whose preferences have been initialized 
from pre-trip sources (onboarding, past trip data, itinerary import). These 
sources provide positive preference signal but no negative signal has been 
observed yet.

For this user's first itinerary:
1. Do not over-concentrate in any single category even if persona dimensions 
   suggest high affinity. Maintain at least 3 distinct category types across 
   the day.
2. Treat all dimension values as estimates with meaningful uncertainty. Prefer 
   candidates that satisfy multiple dimensions over candidates that maximize 
   a single dimension.
3. The first slot swap this user makes is the most important signal in the 
   system. Generate an itinerary that would produce a meaningful negative label 
   if rejected — avoid slots so obviously correct that no rejection is possible.
4. Log your ranking rationale as structured JSON for each slot.
```

Point 3 is counterintuitive but important: an itinerary that's too safe produces no negative signal and slows persona calibration. Some uncertainty in the first itinerary is a feature.

---

## Signal Weight Summary

| Source | Weight | Training Use | Notes |
|---|---|---|---|
| Post-trip thumbs up/down | 1.8× | Persona + ranking | Reflective, deliberate |
| Free text ("trip you've loved") | 1.5× | Persona only | Multi-dimensional reflective |
| On-the-fly manual add | 1.5× | Persona only | Out-of-system discovery |
| Pre-trip slot swap (alteration) | 1.3× | Persona only | Cold, deliberate decision |
| Group vote | 1.2× | Persona only | Deliberate revealed preference |
| In-trip accept / skip | 1.0× | Ranking (warm users) | Baseline. Sunk-cost risk. |
| ChatGPT / LLM paste import | 0.65× | Persona only | Reflects LLM's guess, not behavior |
| Backfill Tier 2 (structured import) | 0.65× | Persona only | No counterfactual |
| Backfill Tier 3 (annotated free-form) | 0.40× | Persona only | No counterfactual |
| First-creation rejection | 0.40× | Persona only | Ambiguous: plan vs. mood |
| Backfill Tier 4 (bare free-form) | 0.20× | Persona only | Lowest confidence, no annotations |
| Cold-user in-trip signal (< 3 trips) | 0.5× | Persona only | Circular: reacting to system's guess |
| Destination prior | 0.15× | Persona init only | Soft nudge, low-confidence dims only |
| Synthetic agent | 0.3× | Persona init only | Never in ranking model |

**Ranking model training gate:** Only signals from warm users (3+ completed trips) with `is_warm_user = true` enter ranking model training. All other signals feed persona dimension training only. Cold-user quarantine prevents circular logic from contaminating the ranking model.

---

## How the Stack Layers Through the User Journey

### Pre-launch (Day -∞ to Day 0)
Synthetic agents generated. 600 persona seeds across 12 archetypes ready. ActivityNode corpus seeded for launch city via Pipeline C. Destination priors computed from corpus data. Nothing requires a real user.

### New user, skips all optional inputs (minimal path)
Scenario cards (2 taps, required) → archetype match → destination prior nudge → destination_persona_prior applied → A11 or matched archetype seeds persona → LLM ranker generates first itinerary. Reasonable quality. Fast.

### New user, completes full onboarding
Scenario cards + free text field → stronger archetype match + destination affinity + category weights from mentioned past cities → 6–8 dimension reads before any trip data → meaningfully better first itinerary.

### New user, backfills past trips
Past trip ingestion → category distribution, pace, food:activity ratio, local/landmark balance extracted → Tier 2–4 confidence weights applied → persona seed substantially better than onboarding alone → first in-app itinerary may feel remarkably accurate.

### New user, pastes ChatGPT itinerary
Full trip shape extracted in one call → category distribution, pace, food:activity ratio, local/landmark balance all parsed → persona seed comparable to 1–2 in-app trips of behavioral data → combined with backfill and onboarding, this user's cold start is essentially solved before they've planned anything in-app.

### System reaches 50+ warm users
Collaborative filtering supplement activates. Cold users' persona seeds now initialized from real warm user centroids, not just synthetic archetypes. The gap between "what we designed the archetypes to be" and "what travelers in this archetype actually do" closes automatically.

### First in-app swap
First negative label arrives. System updates persona dimensions immediately (1.0× weight, persona only). LLM ranker adjusts remaining unconfirmed slots via HLLM Trigger 4 if swap count ≥ 2 within 90 seconds of first reveal. Negative signal territory is now open.

---

## What This Stack Does Not Solve

**Tourist bias in the LLM on Day 1.** Every cold user gets LLM ranking. The LLM has world knowledge about cities that is systematically biased toward popular, well-documented venues. The ActivityNode corpus is built to counteract this (local sources, overrated detector, cross-reference divergence scoring), but the LLM ranker will still have latent tourist bias in how it reasons about candidates. Mitigation: explicit anti-tourist-bias instruction in the cold-user system prompt, and source attribution in the first reveal to make the local sourcing legible to the user.

**Preference drift.** All pre-trip sources reflect who the user was on their past trips. Preferences change. A user whose backfill is full of budget hostels but who now earns more and travels differently will have a miscalibrated persona seed. Mitigation: recency weighting (60-day half-life decay on backfill signals during persona updates) and explicit dimension confidence decay over time without reinforcing signals.

**Group cold start.** The entire stack is designed for individual cold start. Group trips have a separate cold start problem: the system needs multiple individual personas and has to reconcile them immediately on trip 1. This is handled by the Group Dynamics Ranker (Pareto scoring) and Group Split Detector, but those subflows have their own cold start gap — they require 50 group trips before training, which means group trip 1 runs on heuristics only. Acceptable for launch.

---

*Last updated: February 2026*  
*Owner: Kevin*  
*References: overplanned-bootstrap-deepdive.md · overplanned-backfill-enrichment.md · overplanned-onboarding-flow-strategy.md · overplanned-subflow-recommendation-architecture.md · overplanned-heuristics-addendum.md*
