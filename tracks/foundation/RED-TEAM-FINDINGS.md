# Red Team Code Review - Foundation Track
**Date:** 2026-02-20
**Agent:** SOC Red Team (Code-Level Analysis)
**Scope:** Code-level security vulnerabilities in implemented services

---

## Executive Summary

This red team review validates and extends the architectural security review (SECURITY-REVIEW.md) with **code-level vulnerability analysis**. Found **3 CRITICAL** and **6 HIGH** severity issues in the currently implemented FastAPI services that require immediate remediation.

**New Critical Findings:**
- Rate limiting bypass via X-Forwarded-For spoofing
- No authentication on event ingestion endpoint
- Database pool not initialized (runtime crash risk)

---

## CRITICAL Vulnerabilities (Code-Level)

### C-006: Rate Limiting Bypass via Header Spoofing
**Severity:** CRITICAL
**CVSS:** 9.0
**File:** `services/api/middleware/rate_limit.py:36-48`

**Finding:**
```python
def _get_client_key(request: Request) -> tuple[str, bool]:
    user_id = request.state.__dict__.get("user_id")
    if user_id:
        return f"user:{user_id}", True
    # Fall back to IP
    client_ip = request.client.host if request.client else "unknown"
    forwarded = request.headers.get("x-forwarded-for")  # âš ï¸ SPOOFABLE
    if forwarded:
        client_ip = forwarded.split(",")[0].strip()
    return f"ip:{client_ip}", False
```

**Impact:**
Attackers can spoof `X-Forwarded-For` header to bypass rate limiting entirely. Can launch DDoS, credential stuffing, or resource exhaustion attacks.

**Remediation:**
```python
def _get_client_key(request: Request) -> tuple[str, bool]:
    user_id = request.state.__dict__.get("user_id")
    if user_id:
        return f"user:{user_id}", True

    # ONLY trust X-Forwarded-For if behind Cloud Run/Cloud Load Balancer
    # GCP adds X-Cloud-Trace-Context header - validate first
    if settings.environment == "production":
        # Use rightmost IP from X-Forwarded-For (set by load balancer)
        forwarded = request.headers.get("x-forwarded-for", "")
        if forwarded:
            ips = [ip.strip() for ip in forwarded.split(",")]
            # Take LAST IP (closest to server, set by LB)
            client_ip = ips[-1] if ips else "unknown"
        else:
            client_ip = request.client.host if request.client else "unknown"
    else:
        # Local dev: trust direct connection
        client_ip = request.client.host if request.client else "unknown"

    return f"ip:{client_ip}", False
```

**Additional Controls:**
1. Implement IP allowlist for production deployment
2. Use Cloud Armor (GCP WAF) for DDoS protection
3. Add CAPTCHA after N rate limit violations
4. Log rate limit violations with IP + fingerprint

---

### C-007: Unauthenticated Event Ingestion
**Severity:** CRITICAL
**CVSS:** 8.8
**File:** `services/api/routers/events.py:56-119`

**Finding:**
The `/events/batch` endpoint has NO authentication check. Anyone can submit arbitrary events to the database.

```python
@router.post("/batch")
async def ingest_events(body: BatchRequest, request: Request) -> dict:
    # âš ï¸ NO AUTH CHECK - anyone can POST events
    if not body.events:
        return {"success": True, ...}
```

**Impact:**
- Data pollution: inject fake user behavior signals
- Database exhaustion: flood with events until disk full
- Privacy violation: inject events for other users
- Model poisoning: corrupt ML training data with malicious patterns

**Remediation:**
```python
from fastapi import Depends, HTTPException
from services.api.auth import verify_api_key  # TODO: implement

@router.post("/batch")
async def ingest_events(
    body: BatchRequest,
    request: Request,
    api_key: str = Depends(verify_api_key)  # âœ… Require auth
) -> dict:
    # Validate user_id from token matches events
    authenticated_user_id = request.state.user_id

    for event in body.events:
        if event.userId != authenticated_user_id:
            raise HTTPException(
                status_code=403,
                detail="Cannot submit events for other users"
            )

    # ... rest of logic
```

**Additional Controls:**
1. Implement API key authentication (rotate every 90 days)
2. Validate userId matches authenticated user
3. Add event schema validation (reject malformed payloads)
4. Implement write audit logging (who submitted what)
5. Add rate limiting PER USER (not just per IP)

---

### C-008: Database Pool Not Initialized (Runtime Crash)
**Severity:** HIGH (degraded to HIGH from CRITICAL - expected during scaffold)
**CVSS:** 7.5
**File:** `services/api/main.py:49-50`

**Finding:**
```python
# DB pool placeholder â€” wired by database migration task
app.state.db = None
```

Events endpoint will crash when called:
```python
# services/api/routers/events.py:65
db = request.app.state.db  # db is None
async with db.transaction():  # âŒ AttributeError: 'NoneType' has no attribute 'transaction'
```

**Impact:**
All database operations fail with 500 errors. Events endpoint returns INTERNAL_ERROR instead of graceful degradation.

**Remediation:**
```python
# In main.py lifespan
from asyncpg import create_pool

async def lifespan(app: FastAPI):
    # ... existing code

    # Initialize asyncpg pool
    try:
        db_pool = await create_pool(
            settings.database_url,
            min_size=5,
            max_size=20,
            command_timeout=10,
            server_settings={'application_name': 'overplanned-api'}
        )
        app.state.db = db_pool
    except Exception as e:
        # Log error but don't crash on startup
        logger.error(f"Failed to initialize DB pool: {e}")
        app.state.db = None

    yield

    if app.state.db:
        await app.state.db.close()

# In events.py
@router.post("/batch")
async def ingest_events(body: BatchRequest, request: Request) -> dict:
    db = request.app.state.db
    if db is None:
        raise HTTPException(
            status_code=503,
            detail="Database unavailable"
        )
    # ... rest of logic
```

---

## HIGH Severity Vulnerabilities (Code-Level)

### H-011: No Request Logging or Audit Trail
**File:** All routers
**CVSS:** 7.8

**Finding:**
No structured logging of API requests. Impossible to audit who did what, detect anomalies, or investigate incidents.

**Remediation:**
```python
import structlog

logger = structlog.get_logger()

@app.middleware("http")
async def audit_logging_middleware(request: Request, call_next):
    start_time = time.time()

    # Log request
    logger.info(
        "api.request",
        method=request.method,
        path=request.url.path,
        client_ip=_get_client_key(request)[0],
        user_id=request.state.__dict__.get("user_id"),
        request_id=request.state.request_id,
    )

    response = await call_next(request)

    # Log response
    logger.info(
        "api.response",
        status_code=response.status_code,
        duration_ms=(time.time() - start_time) * 1000,
        request_id=request.state.request_id,
    )

    return response
```

---

### H-012: Exception Handlers Leak Stack Traces (in debug mode)
**File:** `services/api/main.py:138-176`
**CVSS:** 7.2

**Finding:**
Exception handlers return generic errors, but in debug mode or if Sentry fails, stack traces may leak to clients.

**Remediation:**
```python
import traceback
from services.api.logging import logger

@app.exception_handler(Exception)  # Catch-all
async def global_exception_handler(request: Request, exc: Exception) -> JSONResponse:
    request_id = getattr(request.state, "request_id", str(uuid.uuid4()))

    # NEVER leak stack trace to client
    logger.error(
        "unhandled_exception",
        exc_info=exc,
        request_id=request_id,
        path=request.url.path,
        method=request.method,
    )

    # Generic error to client
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": {
                "code": "INTERNAL_ERROR",
                "message": "An unexpected error occurred.",
                "requestId": request_id,  # For support lookup
            },
        },
    )
```

---

### H-013: No Security Headers
**File:** `services/api/main.py` (missing)
**CVSS:** 7.0

**Finding:**
No security headers (CSP, X-Frame-Options, etc.). Vulnerable to clickjacking, MIME sniffing, XSS.

**Remediation:**
```python
@app.middleware("http")
async def security_headers_middleware(request: Request, call_next) -> Response:
    response = await call_next(request)

    # Security headers
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-XSS-Protection"] = "1; mode=block"
    response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
    response.headers["Permissions-Policy"] = "geolocation=(), microphone=(), camera=()"

    # CSP (adjust for your needs)
    if settings.environment == "production":
        response.headers["Content-Security-Policy"] = (
            "default-src 'self'; "
            "script-src 'self'; "
            "style-src 'self' 'unsafe-inline'; "
            "img-src 'self' data:; "
            "connect-src 'self' https://o123456.ingest.sentry.io; "
            "frame-ancestors 'none'"
        )

    return response
```

---

### H-014: Qdrant API Key Stored in Plaintext Config
**File:** `services/api/config.py:40`
**CVSS:** 7.0

**Finding:**
```python
qdrant_api_key: str = ""  # Read from env var (plaintext)
```

**Remediation:**
1. Use GCP Secret Manager in production:
```python
from google.cloud import secretmanager

def get_secret(secret_id: str) -> str:
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{PROJECT_ID}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(request={"name": name})
    return response.payload.data.decode("UTF-8")

# In config
if settings.environment == "production":
    qdrant_api_key = get_secret("qdrant-api-key")
else:
    qdrant_api_key = os.getenv("QDRANT_API_KEY", "")
```

---

### H-015: No Request Size Validation (except /events/batch)
**File:** All routers except events.py
**CVSS:** 6.8

**Finding:**
Only `/events/batch` has body size validation. Other endpoints can accept arbitrarily large payloads.

**Remediation:**
```python
@app.middleware("http")
async def request_size_limit_middleware(request: Request, call_next) -> Response:
    # Default 10MB limit
    max_bytes = 10_485_760

    # Per-endpoint overrides
    if request.url.path == "/events/batch":
        max_bytes = settings.events_request_max_bytes
    elif request.url.path.startswith("/embed/"):
        max_bytes = 1_048_576  # 1MB for embeddings

    content_length = request.headers.get("content-length")
    if content_length and int(content_length) > max_bytes:
        return JSONResponse(
            status_code=413,
            content={
                "success": False,
                "error": {
                    "code": "PAYLOAD_TOO_LARGE",
                    "message": f"Request body exceeds {max_bytes} bytes.",
                },
            },
        )

    return await call_next(request)
```

---

### H-016: Redis Connection Not Validated on Startup
**File:** `services/api/main.py:33-44`
**CVSS:** 6.5

**Finding:**
```python
try:
    redis_client = aioredis.from_url(...)
    await redis_client.ping()
except Exception:
    redis_client = None  # Silent failure
```

**Impact:**
Rate limiting silently degrades. Attackers can DDoS if Redis is down and no one notices.

**Remediation:**
```python
try:
    redis_client = aioredis.from_url(...)
    await redis_client.ping()
    logger.info("redis.connected")
except Exception as e:
    logger.error("redis.connection_failed", error=str(e))
    redis_client = None

    # In production, FAIL FAST if Redis is critical
    if settings.environment == "production":
        raise RuntimeError("Redis connection required in production") from e
```

---

### H-017: Qdrant Collection Not Validated
**File:** `services/api/search/service.py` (not shown but inferred)
**CVSS:** 6.3

**Finding:**
Search service likely queries Qdrant collection without validating it exists first.

**Remediation:**
```python
# In QdrantSearchClient
async def ensure_collection_exists(self, collection_name: str):
    collections = await self.client.get_collections()
    if collection_name not in [c.name for c in collections.collections]:
        raise RuntimeError(f"Qdrant collection '{collection_name}' does not exist")

# In lifespan
await app.state.qdrant.ensure_collection_exists("activities")
```

---

## Medium Severity Issues

### M-011: No Health Check Readiness vs Liveness
**File:** `services/api/routers/health.py` (not reviewed but likely simple)

**Finding:**
Health check likely just returns 200. Should distinguish readiness (can serve traffic) vs liveness (process alive).

**Remediation:**
```python
@router.get("/health/live")
async def liveness():
    return {"status": "alive"}

@router.get("/health/ready")
async def readiness(request: Request):
    checks = {}

    # Check Redis
    redis = request.app.state.redis
    checks["redis"] = "up" if redis else "down"

    # Check DB
    db = request.app.state.db
    if db:
        try:
            await db.fetch("SELECT 1")
            checks["database"] = "up"
        except:
            checks["database"] = "down"
    else:
        checks["database"] = "down"

    # Check Qdrant
    try:
        await request.app.state.qdrant.client.get_collections()
        checks["qdrant"] = "up"
    except:
        checks["qdrant"] = "down"

    all_up = all(v == "up" for v in checks.values())
    return JSONResponse(
        status_code=200 if all_up else 503,
        content={"status": "ready" if all_up else "degraded", "checks": checks}
    )
```

---

### M-012: CORS Allows Credentials Without Strict Origin Check
**File:** `services/api/middleware/cors.py:16`

**Finding:**
```python
allow_credentials=True,
allow_origins=settings.cors_origins,
```

**Issue:**
If `cors_origins` includes a wildcard or is misconfigured, credentials can leak cross-origin.

**Remediation:**
1. NEVER use wildcard with credentials
2. Validate origins at runtime:
```python
def setup_cors(app: FastAPI) -> None:
    # Validate no wildcards
    if "*" in settings.cors_origins:
        raise ValueError("CORS wildcards not allowed with credentials")

    app.add_middleware(
        CORSMiddleware,
        allow_origins=settings.cors_origins,
        allow_credentials=True,
        # ... rest
    )
```

---

### M-013: No Request ID Validation
**File:** `services/api/main.py:98`

**Finding:**
```python
request_id = request.headers.get("x-request-id", str(uuid.uuid4()))
```

**Issue:**
Client can inject malicious request IDs (XSS in logs, log injection).

**Remediation:**
```python
import re

REQUEST_ID_PATTERN = re.compile(r"^[a-f0-9\-]{36}$")  # UUID format

request_id = request.headers.get("x-request-id", "")
if request_id and REQUEST_ID_PATTERN.match(request_id):
    request_id = request_id
else:
    request_id = str(uuid.uuid4())
```

---

## Compliance Issues (Code-Level)

### GDPR Data Minimization Violation
**File:** `services/api/middleware/rate_limit.py`

**Finding:**
Storing full IP addresses in Redis sorted sets for rate limiting. Should hash or anonymize.

**Remediation:**
```python
import hashlib

def _hash_ip(ip: str, date_salt: str) -> str:
    """Hash IP with daily rotating salt for privacy."""
    return hashlib.sha256(f"{ip}:{date_salt}".encode()).hexdigest()[:16]

# In rate limiter
client_key, is_authenticated = _get_client_key(request)
if not is_authenticated:
    # Hash IP addresses for privacy
    date_salt = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    if client_key.startswith("ip:"):
        ip = client_key[3:]
        client_key = f"ip:{_hash_ip(ip, date_salt)}"
```

---

## Prioritized Remediation Checklist

### ðŸ”´ CRITICAL (Block All Deployments)
- [ ] **C-006**: Fix X-Forwarded-For header spoofing in rate limiter
- [ ] **C-007**: Add authentication to /events/batch endpoint
- [ ] **C-008**: Initialize database pool properly (handle None case)

### ðŸŸ  HIGH (Block Production)
- [ ] **H-011**: Add structured request/response logging
- [ ] **H-012**: Ensure no stack trace leaks in error handlers
- [ ] **H-013**: Add security headers middleware
- [ ] **H-014**: Use Secret Manager for Qdrant API key (production)
- [ ] **H-015**: Add global request size validation
- [ ] **H-016**: Fail fast on Redis connection failure (production)

### ðŸŸ¡ MEDIUM (Before Beta)
- [ ] **M-011**: Implement readiness vs liveness health checks
- [ ] **M-012**: Validate CORS config has no wildcards
- [ ] **M-013**: Validate client request IDs

### ðŸ“‹ GDPR Compliance
- [ ] Hash IP addresses in rate limiting with daily rotation
- [ ] Add data retention policy for Redis keys (90 days)

---

## Testing Recommendations

### Automated Security Tests
```python
# tests/security/test_rate_limit_bypass.py
def test_rate_limit_cannot_be_bypassed_with_spoofed_header():
    """Verify X-Forwarded-For spoofing doesn't bypass rate limits."""
    client = TestClient(app)

    for i in range(100):
        # Try to bypass by changing X-Forwarded-For
        response = client.post(
            "/events/batch",
            json={"events": []},
            headers={"X-Forwarded-For": f"1.2.3.{i}"}
        )

    # Should be rate limited (same source IP)
    assert response.status_code == 429

# tests/security/test_auth_required.py
def test_events_endpoint_requires_authentication():
    """Verify events cannot be submitted without auth."""
    client = TestClient(app)
    response = client.post("/events/batch", json={"events": []})
    assert response.status_code == 401  # or 403

# tests/security/test_security_headers.py
def test_security_headers_present():
    """Verify all security headers are set."""
    client = TestClient(app)
    response = client.get("/health")

    assert response.headers["X-Content-Type-Options"] == "nosniff"
    assert response.headers["X-Frame-Options"] == "DENY"
    assert "Content-Security-Policy" in response.headers
```

---

## Sign-Off

**Code-level security review COMPLETE.** All CRITICAL and HIGH issues must be remediated before production deployment. The architectural review (SECURITY-REVIEW.md) combined with this code review provides comprehensive security coverage.

**Estimated Remediation Effort:**
- CRITICAL issues: 8-16 hours (1-2 days)
- HIGH issues: 16-24 hours (2-3 days)
- MEDIUM issues: 8 hours (1 day)

**Total:** 4-6 days for complete security hardening.

---

**Reviewed By:** SOC Red Team Agent (Code-Level)
**Review Date:** 2026-02-20
**Next Review:** After remediation + before production deploy
